{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unets.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZVoD_ZSdU5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import util"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1VKY5Jqkab3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7097e512-7165-4a0e-e020-3706ef8579c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G10174rGdm_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptions, images = util.make_descriptions_and_images()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCMlqVCFrFP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels, classes, class_to_index = util.make_labels_and_classes(descriptions)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5tPpKi06qiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_masks = np.zeros((size, 512, 640), np.uint8)\n",
        "for i, descr in enumerate(descriptions):\n",
        "  for shape in descr['shapes']:\n",
        "    cv2.fillPoly(true_masks[i], [np.array(shape['points'])], 1)\n",
        "#true_masks = true_masks[:, None, :, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl-a2ecD6BND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 4\n",
        "X, y = np.empty((n_classes, 0)).tolist(), np.empty((n_classes, 0)).tolist()\n",
        "for class_, indexes in labels.items():\n",
        "  current_class = class_to_index[class_]\n",
        "  if (current_class > 2):\n",
        "    continue\n",
        "  for index in indexes:\n",
        "    current_class = class_to_index[class_]\n",
        "    if current_class == 0:\n",
        "      if images[index].mean(axis=(0, 1))[1] >= 150:\n",
        "        current_class = 3\n",
        "    X[current_class].append(images[index])\n",
        "    y[current_class].append(true_masks[index])\n",
        "X = list(map(np.array, X))\n",
        "y = list(map(np.array, y))\n",
        "X[0].shape, X[1].shape, X[2].shape, X[3].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxcMrYTP8aBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mins, diffs = [[], [], [], [], [], []], [[], [], [], [], [], []]\n",
        "for i in range(n_classes):\n",
        "  min_, max_ = X[i].min(axis=0), X[i].max(axis=0)\n",
        "  diff = max_ - min_\n",
        "  del max_\n",
        "  mins[0].append(min_.transpose(2, 0, 1).astype(np.uint8))\n",
        "  diffs[0].append(diff.transpose(2, 0, 1).astype(np.uint8))\n",
        "  min_im = Image.fromarray(min_)\n",
        "  diff_im = Image.fromarray(diff)\n",
        "  for j in range(1, 4):\n",
        "    mins[j].append(np.asarray(min_im.rotate(90 * j, expand=True)).transpose(2, 0, 1).astype(np.uint8))\n",
        "    diffs[j].append(np.asarray(diff_im.rotate(90 * j, expand=True)).transpose(2, 0, 1).astype(np.uint8))\n",
        "  mins[4].append(np.asarray(min_im.transpose(Image.FLIP_TOP_BOTTOM)).transpose(2, 0, 1))\n",
        "  diffs[4].append(np.asarray(diff_im.transpose(Image.FLIP_TOP_BOTTOM)).transpose(2, 0, 1))\n",
        "  mins[5].append(np.asarray(min_im.transpose(Image.FLIP_LEFT_RIGHT)).transpose(2, 0, 1))\n",
        "  diffs[5].append(np.asarray(diff_im.transpose(Image.FLIP_LEFT_RIGHT)).transpose(2, 0, 1))\n",
        "for i in range(n_classes):\n",
        "  for j in range(6):\n",
        "    diffs[j][i] = np.where((diffs[j][i] == 0), np.inf, diffs[j][i])\n",
        "def scale(X, class_, rotate):\n",
        "  return 2 * (X - mins[rotate][class_]) / diffs[rotate][class_] - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QET73V8pdwEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mins_save = np.array(mins[0])\n",
        "diffs_save = np.array(diffs[0])\n",
        "np.save('/content/drive/My Drive/ml_contests/digital_breakthrough/first4_mins.npy', mins_save)\n",
        "np.save('/content/drive/My Drive/ml_contests/digital_breakthrough/first4_diffs.npy', diffs_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFPkH3hw9RcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train, X_test, y_train, y_test = np.empty((n_classes, 0)).tolist(), np.empty((n_classes, 0)).tolist(),\\\n",
        "#                                   np.empty((n_classes, 0)).tolist(), np.empty((n_classes, 0)).tolist()\n",
        "X_train_rotation = np.empty((n_classes, 0)).tolist()\n",
        "X_train_rotation_rot = np.empty((n_classes, 0)).tolist()\n",
        "X_train_aug, y_train_aug = np.empty((n_classes, 0)).tolist(), np.empty((n_classes, 0)).tolist()\n",
        "X_train_aug_rot, y_train_aug_rot = np.empty((n_classes, 0)).tolist(), np.empty((n_classes, 0)).tolist()\n",
        "for i in range(n_classes):\n",
        "  #X_train[i], X_test[i], y_train[i], y_test[i] = map(np.ndarray.tolist, train_test_split(X[i], y[i], test_size=0.33))\n",
        "  len_ = len(X[i])\n",
        "  for j in range(len_):\n",
        "    im = Image.fromarray(np.array(X[i][j], dtype=np.uint8))\n",
        "    X_train_aug[i].append(np.asarray(im).transpose(2, 0, 1))\n",
        "    im2 = im.rotate(90, expand=True)\n",
        "    X_train_aug_rot[i].append(np.asarray(im2).transpose(2, 0, 1))\n",
        "    im3 = im2.rotate(90, expand=True)\n",
        "    X_train_aug[i].append(np.asarray(im3).transpose(2, 0, 1))\n",
        "    im4 = im3.rotate(90, expand=True)\n",
        "    X_train_aug_rot[i].append(np.asarray(im4).transpose(2, 0, 1))\n",
        "    \n",
        "    X_train_aug[i].append(np.asarray(im.transpose(Image.FLIP_TOP_BOTTOM)).transpose(2, 0, 1))\n",
        "    X_train_aug[i].append(np.asarray(im.transpose(Image.FLIP_LEFT_RIGHT)).transpose(2, 0, 1))\n",
        "    X_train_rotation[i] += [0, 2, 4, 5]\n",
        "    X_train_rotation_rot[i] += [1, 3]\n",
        "  for j in range(len_):\n",
        "    im = Image.fromarray(np.array(y[i][j], dtype=np.uint8))\n",
        "    y_train_aug[i].append(np.asarray(im)[None, :, :])\n",
        "    im2 = im.rotate(90, expand=True)\n",
        "    y_train_aug_rot[i].append(np.asarray(im2)[None, :, :])\n",
        "    im3 = im2.rotate(90, expand=True)\n",
        "    y_train_aug[i].append(np.asarray(im3)[None, :, :])\n",
        "    im4 = im3.rotate(90, expand=True)\n",
        "    y_train_aug_rot[i].append(np.asarray(im4)[None, :, :])\n",
        "    \n",
        "    y_train_aug[i].append(np.asarray(im.transpose(Image.FLIP_TOP_BOTTOM))[None, :, :])\n",
        "    y_train_aug[i].append(np.asarray(im.transpose(Image.FLIP_LEFT_RIGHT))[None, :, :])\n",
        "#X_train = list(map(np.array, X_train))\n",
        "#X_test = list(map(np.array, X_test))\n",
        "#del X_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZvfy2WKnDr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95fa201a-c887-4805-9916-ac6d0a04badb"
      },
      "source": [
        "np.array(X_train_aug[0]).shape, np.array(X_train_aug[1]).shape, np.array(X_train_aug[2]).shape, np.array(X_train_aug[3]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((136, 3, 512, 640), (372, 3, 512, 640), (56, 3, 512, 640), (144, 3, 512, 640))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jINh3TM2n5d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = list(map(np.array, y_test))\n",
        "for i in range(n_classes):\n",
        "  y_test[i] = y_test[i][:, None, :, :]\n",
        "X_test = list(map(np.array, X_test))\n",
        "for i in range(n_classes):\n",
        "  X_test[i] = X_test[i].transpose(0, 3, 1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E8xn71jxEpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dataset(data.Dataset):\n",
        "  def __init__(self, data, y, class_):\n",
        "    self.rotation = data[1]\n",
        "    self.len = len(data[0])\n",
        "    self.x = data[0]\n",
        "    self.y = y\n",
        "    self.class_ = class_\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "  def __getitem__(self, id):\n",
        "    #print(self.class_, ' ', id, ' ', self.rotation[id])\n",
        "    return (scale(self.x[id], self.class_, self.rotation[id]), self.y[id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahuAiqwKRIe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datas, test_datas = np.empty((2 * n_classes, 0)).tolist(), np.empty((n_classes, 0)).tolist()\n",
        "for i in range(n_classes):\n",
        "  train_dataset = dataset((X_train_aug[i], X_train_rotation[i]), y_train_aug[i], i)\n",
        "  train_dataset_rot = dataset((X_train_aug_rot[i], X_train_rotation_rot[i]), y_train_aug_rot[i], i)\n",
        "  #test_dataset = dataset((X_test[i], np.zeros(X_test[i].shape[0], dtype=int)), y_test[i], i)\n",
        "  batch_size = 4\n",
        "\n",
        "  train_datas[i] = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  train_datas[n_classes + i] = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  #test_datas[i] = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQx-AhXJxavh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_size = 512\n",
        "class Unet(nn.Module):\n",
        "  def __init__(self): # 512, 512\n",
        "    super(Unet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, max_size // 16, 3, padding=1) \n",
        "    self.conv2 = nn.Conv2d(max_size // 16, max_size // 16, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(max_size // 16, max_size // 8, 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(max_size // 8, max_size // 8, 3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(max_size // 8, max_size // 4, 3, padding=1)\n",
        "    self.conv6 = nn.Conv2d(max_size // 4, max_size // 4, 3, padding=1)\n",
        "    self.conv7 = nn.Conv2d(max_size // 4, max_size // 2, 3, padding=1)\n",
        "    self.conv8 = nn.Conv2d(max_size // 2, max_size // 2, 3, padding=1)\n",
        "    self.conv9 = nn.Conv2d(max_size // 2, max_size, 3, padding=1)\n",
        "    self.conv10 = nn.Conv2d(max_size, max_size, 3, padding=1)\n",
        "    \n",
        "    self.upconv1 = nn.ConvTranspose2d(max_size, max_size // 2, 2, 2)\n",
        "    self.conv11 = nn.Conv2d(max_size, max_size // 2, 3, padding=1)\n",
        "    self.conv12 = nn.Conv2d(max_size // 2, max_size // 2, 3, padding=1)\n",
        "\n",
        "    self.upconv2 = nn.ConvTranspose2d(max_size // 2, max_size // 4, 2, 2)\n",
        "    self.conv13 = nn.Conv2d(max_size // 2, max_size // 4, 3, padding=1)\n",
        "    self.conv14 = nn.Conv2d(max_size // 4, max_size // 4, 3, padding=1)\n",
        "\n",
        "    self.upconv3 = nn.ConvTranspose2d(max_size // 4, max_size // 8, 2, 2)\n",
        "    self.conv15 = nn.Conv2d(max_size // 4, max_size // 8, 3, padding=1)\n",
        "    self.conv16 = nn.Conv2d(max_size // 8, max_size // 8, 3, padding=1)\n",
        "\n",
        "    self.upconv4 = nn.ConvTranspose2d(max_size // 8, max_size // 16, 2, 2)\n",
        "    self.conv17 = nn.Conv2d(max_size // 8, max_size // 16, 3, padding=1)\n",
        "    self.conv18 = nn.Conv2d(max_size // 16, max_size // 16, 3, padding=1)\n",
        "\n",
        "    self.conv19 = nn.Conv2d(max_size // 16, 2, 1)\n",
        "    self.a = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "  def forward(self, x): # 512, 640 \n",
        "    c1 = self.a(self.conv2(self.a(self.conv1(x)))) # 8 512 640 <- 8 512 640 <- 3 512 640\n",
        "    p1 = self.pool(c1) # 8 256, 320\n",
        "    c2 = self.a(self.conv4(self.a(self.conv3(p1)))) # 16 256 320 <- 16 256 320 <- 8 256 320\n",
        "    p2 = self.pool(c2) # 128, 160\n",
        "    c3 = self.a(self.conv6(self.a(self.conv5(p2)))) # 32 128 160 <- 32 128 160 <- 16 128 160\n",
        "    p3 = self.pool(c3) # 64, 80\n",
        "    c4 = self.a(self.conv8(self.a(self.conv7(p3)))) # 64 64 80 <- 64 64 80 <- 32 64 80\n",
        "    p4 = self.pool(c4) # 32, 40\n",
        "    c5 = self.a(self.conv10(self.a(self.conv9(p4)))) # 128 32 40 <- 128 32 40 <- 64 32 40\n",
        "    #print(c4.shape, ' ', c5.shape, ' ', self.upconv1(c5).shape)\n",
        "    u6 = torch.cat((self.upconv1(c5), c4), dim=1)  # 128 64 80 <- 64 64 80 <- 128 32 40\n",
        "    c6 = self.a(self.conv12(self.a(self.conv11(u6)))) # 64 64 80 <- 64 64 80 <- 128 64 80\n",
        "    u7 = torch.cat((self.upconv2(c6), c3), dim=1) # 64 128 160 <- 32 128 160 <- 64 64 80\n",
        "    c7 = self.a(self.conv14(self.a(self.conv13(u7)))) # 32 128 160 <- 32 128 160 <- 64 128 160\n",
        "    u8 = torch.cat((self.upconv3(c7), c2), dim=1) # 32 256 320 <- 16 256 320 <- 32 128 160\n",
        "    c8 = self.a(self.conv16(self.a(self.conv15(u8)))) # 16 256 320 <- 16 256 320 <- 32 256 320\n",
        "    u9 = torch.cat((self.upconv4(c8), c1), dim=1) # 16 512 640 <- 8 512 640 <- 16 256 320\n",
        "    c9 = self.a(self.conv18(self.a(self.conv17(u9)))) # 8 512 640 <- 8 512 640 <- 16 512 640\n",
        "\n",
        "    return self.conv19(c9) # 2 512 640 <- 8 512 640"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00CHakr8RGuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_loss(x, y):\n",
        "  return (1 - (2 * (x * y).sum(dim=(2, 3)) / (x.sum(dim=(2, 3)) + y.sum(dim=(2, 3)))).mean(dim=(0, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25t5R3nVREyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRYyTPjjQDDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss1 = nn.CrossEntropyLoss()\n",
        "loss2 = dice_loss\n",
        "u_models = np.empty((n_classes, 0)).tolist()\n",
        "optims = np.empty((n_classes, 0)).tolist()\n",
        "for i in range(n_classes):\n",
        "  u_models[i] = Unet().double().to(device)\n",
        "  optims[i] = torch.optim.Adam(u_models[i].parameters(), lr=0.0005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x1Sopsa4tDHh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d79845e-8d2d-4245-c6db-a7691a708a2b"
      },
      "source": [
        "active = nn.Softmax2d()\n",
        "for epoch in range(20):\n",
        "    train_batch_loss = [[], [], [], []]\n",
        "    test_batch_loss = [[], [], [], []]\n",
        "    train_batch_score = [[], [], [], []]\n",
        "    test_batch_score = [[], [], [], []]\n",
        "    start_epoch = time.time()\n",
        "    for i, train_data in enumerate(train_datas):\n",
        "      if i >= n_classes:\n",
        "        i -= n_classes\n",
        "      u_models[i].train()\n",
        "      for batch in train_data:\n",
        "        start_batch = time.time()\n",
        "        optims[i].zero_grad()\n",
        "        scores = u_models[i](batch[0].to(device=device))\n",
        "        predections = scores.argmax(dim=1).cpu().detach().numpy()\n",
        "        batch[1] = batch[1].long().to(device=device)\n",
        "        groud_truth = batch[1].squeeze(dim=1)\n",
        "        current_loss = loss1(scores, groud_truth) + loss2(active(scores), torch.cat((batch[1].logical_not().long(), batch[1]), dim=1))\n",
        "        current_loss.backward()\n",
        "        optims[i].step()\n",
        "        train_batch_loss[i].append(current_loss.item())\n",
        "        groud_truth = groud_truth.cpu().detach().numpy()\n",
        "        train_batch_score[i] += (np.count_nonzero(np.logical_and(groud_truth, predections), axis=(1, 2)) / \n",
        "                                    np.count_nonzero(np.logical_or(groud_truth, predections), axis=(1, 2))).tolist()\n",
        "    \n",
        "    \n",
        "    for i, test_data in enumerate(test_datas):\n",
        "      u_models[i].eval()\n",
        "      for batch in test_data:\n",
        "        scores = u_models[i](batch[0].to(device=device))\n",
        "        predections = scores.argmax(dim=1).cpu().detach().numpy()\n",
        "        batch[1] = batch[1].long().to(device=device)\n",
        "        groud_truth = batch[1].squeeze(dim=1)\n",
        "        current_loss = loss1(scores, batch[1].squeeze(dim=1)) + loss2(active(scores), torch.cat((batch[1].logical_not().long(), batch[1]), dim=1))\n",
        "        test_batch_loss[i].append(current_loss.item())\n",
        "        groud_truth = groud_truth.cpu().detach().numpy()\n",
        "        test_batch_score[i] += (np.count_nonzero(np.logical_and(groud_truth, predections), axis=(1, 2)) / \n",
        "                                  np.count_nonzero(np.logical_or(groud_truth, predections), axis=(1, 2))).tolist()\n",
        "    \n",
        "    cetrl, cettl, trbs, ttbs = np.zeros(n_classes), np.zeros(n_classes), np.zeros(n_classes), np.zeros(n_classes), \n",
        "    for j in range(n_classes):\n",
        "      cetrl[j] = np.mean(train_batch_loss[j])\n",
        "      cettl[j] = np.mean(test_batch_loss[j]) \n",
        "      trbs[j] = np.mean(train_batch_score[j])\n",
        "      ttbs[j] = np.mean(test_batch_score[j])\n",
        "    print(epoch, \" time took - \", time.time() - start_epoch, \"\\ntrain_loss = \", cetrl, \"\\ntest_loss = \", cettl, '\\ntrain score = ', trbs, '\\ntest score = ', ttbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0  time took -  491.9342532157898 \n",
            "train_loss =  [0.80722819 0.618451   1.04355644 0.945009  ] \n",
            "test_loss =  [0.62829842 0.37586302 0.56504842 0.7732091 ] \n",
            "train score =  [0.         0.0083714  0.00747949 0.00432936] \n",
            "test score =  [0.         0.22649061 0.         0.        ]\n",
            "1  time took -  491.64195108413696 \n",
            "train_loss =  [0.50810538 0.18317762 0.62764598 0.69430403] \n",
            "test_loss =  [0.29683626 0.12696378 0.57251429 0.61683554] \n",
            "train score =  [0.         0.59363788 0.         0.        ] \n",
            "test score =  [0.        0.6910495 0.        0.       ]\n",
            "2  time took -  491.41602873802185 \n",
            "train_loss =  [0.23365665 0.0997813  0.61243527 0.46575063] \n",
            "test_loss =  [0.0813315  0.09069327 0.55274237 0.36107215] \n",
            "train score =  [0.62823185 0.72089017 0.         0.31763101] \n",
            "test score =  [0.8012017  0.74026556 0.         0.58723301]\n",
            "3  time took -  491.5036549568176 \n",
            "train_loss =  [0.07578415 0.09054568 0.5869711  0.20623085] \n",
            "test_loss =  [0.07175322 0.0819265  0.52776877 0.16746264] \n",
            "train score =  [0.81607699 0.74273127 0.         0.69826988] \n",
            "test score =  [0.81756123 0.76298492 0.         0.68788433]\n",
            "4  time took -  491.54079937934875 \n",
            "train_loss =  [0.06733683 0.08256116 0.457761   0.11755823] \n",
            "test_loss =  [0.07050031 0.08140014 0.35947816 0.07622074] \n",
            "train score =  [0.82703359 0.76124748 0.14835195 0.7954662 ] \n",
            "test score =  [0.82000103 0.76733813 0.5184799  0.86039717]\n",
            "5  time took -  491.16116404533386 \n",
            "train_loss =  [0.06510675 0.07751902 0.31207894 0.07771405] \n",
            "test_loss =  [0.06879519 0.09411678 0.32337883 0.06469934] \n",
            "train score =  [0.83130382 0.77319611 0.47551267 0.85263327] \n",
            "test score =  [0.82300957 0.74240462 0.47906685 0.86946289]\n",
            "6  time took -  491.34116530418396 \n",
            "train_loss =  [0.06738331 0.07585966 0.25960675 0.06945502] \n",
            "test_loss =  [0.07215369 0.08262987 0.10255034 0.05531892] \n",
            "train score =  [0.82676145 0.7786403  0.52615158 0.86120976] \n",
            "test score =  [0.81664337 0.76419619 0.66596455 0.8780712 ]\n",
            "7  time took -  491.36751437187195 \n",
            "train_loss =  [0.06950324 0.07625009 0.18821691 0.06161146] \n",
            "test_loss =  [0.09396136 0.06926033 0.22125067 0.05016203] \n",
            "train score =  [0.82168148 0.77750286 0.61242681 0.87403323] \n",
            "test score =  [0.77209852 0.7957885  0.53630225 0.88964543]\n",
            "8  time took -  491.4387707710266 \n",
            "train_loss =  [0.06638881 0.06899773 0.1986036  0.04713547] \n",
            "test_loss =  [0.07790102 0.07075813 0.17261074 0.05008788] \n",
            "train score =  [0.82809955 0.79532267 0.6002299  0.89884485] \n",
            "test score =  [0.80557483 0.79052047 0.64842618 0.89471761]\n",
            "9  time took -  491.1282248497009 \n",
            "train_loss =  [0.06358217 0.06187491 0.14233963 0.08933673] \n",
            "test_loss =  [0.07097714 0.06700644 0.09829558 0.2382463 ] \n",
            "train score =  [0.83198688 0.81385264 0.68330155 0.84164415] \n",
            "test score =  [0.81667009 0.80285848 0.74946147 0.59638955]\n",
            "10  time took -  491.3010563850403 \n",
            "train_loss =  [0.0644999  0.0585049  0.12809269 0.11232244] \n",
            "test_loss =  [0.06939391 0.06498915 0.11736583 0.04590768] \n",
            "train score =  [0.83076437 0.8230535  0.71023045 0.82135111] \n",
            "test score =  [0.81878516 0.80804591 0.69083375 0.89909106]\n",
            "11  time took -  491.46717262268066 \n",
            "train_loss =  [0.05999882 0.05842102 0.1152805  0.05687129] \n",
            "test_loss =  [0.0696571  0.06277059 0.06506912 0.05410157] \n",
            "train score =  [0.83896222 0.82390761 0.73614257 0.8843796 ] \n",
            "test score =  [0.8178871  0.81374328 0.81267013 0.88987053]\n",
            "12  time took -  491.2052719593048 \n",
            "train_loss =  [0.05888747 0.05912088 0.11520953 0.05044509] \n",
            "test_loss =  [0.07176091 0.06771758 0.0677478  0.05787284] \n",
            "train score =  [0.84144549 0.82215424 0.73597469 0.89131157] \n",
            "test score =  [0.81197119 0.80428495 0.83048242 0.8755687 ]\n",
            "13  time took -  491.3559000492096 \n",
            "train_loss =  [0.05810537 0.05798989 0.12097078 0.04996463] \n",
            "test_loss =  [0.07361208 0.06819584 0.09653493 0.05096836] \n",
            "train score =  [0.8442661  0.82487667 0.72509364 0.8938928 ] \n",
            "test score =  [0.80692555 0.79900013 0.73645879 0.89366304]\n",
            "14  time took -  491.26497197151184 \n",
            "train_loss =  [0.05799913 0.05413722 0.12401915 0.03746121] \n",
            "test_loss =  [0.06514824 0.06519306 0.12512713 0.04112684] \n",
            "train score =  [0.84515968 0.83547138 0.71782629 0.91668858] \n",
            "test score =  [0.82268479 0.80895778 0.7348407  0.90851612]\n",
            "15  time took -  491.2604398727417 \n",
            "train_loss =  [0.05606567 0.04922237 0.12315219 0.0344908 ] \n",
            "test_loss =  [0.06561232 0.06202785 0.04767286 0.03932949] \n",
            "train score =  [0.84912316 0.8484193  0.7253187  0.92266819] \n",
            "test score =  [0.82418205 0.81695809 0.85604969 0.91094995]\n",
            "16  time took -  491.2220253944397 \n",
            "train_loss =  [0.05367645 0.04894989 0.10190411 0.04175127] \n",
            "test_loss =  [0.07242495 0.06639752 0.04193538 0.04236791] \n",
            "train score =  [0.85495625 0.84931524 0.76140076 0.90918297] \n",
            "test score =  [0.81068195 0.8055685  0.87815789 0.90500512]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cb1ZBoN3kRuZ",
        "colab": {}
      },
      "source": [
        "# 0 - 6, 1 - 12, 2 - 17, 3 - 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRFrQrNUBxST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5q7s1vf4uJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFvQ7QPVBxpP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77c135f7-0427-4f84-c766-9605543d1df7"
      },
      "source": [
        "# bn+tanh only 4 last 20 epoches"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  time took -  334.73125195503235 \n",
            "train_loss =  [1.27510557 1.12598527 1.34790749 1.14931956] \n",
            "test_loss =  [1.19712935 0.82487849 1.23548838 1.10489169] \n",
            "train score =  [0.01507985 0.02053684 0.00549052 0.02816047] \n",
            "test score =  [0.04048506 0.00316424 0.00757537 0.01362815]\n",
            "1  time took -  334.51902437210083 \n",
            "train_loss =  [1.08527119 0.74162772 1.06511032 0.84611308] \n",
            "test_loss =  [1.02027778 0.61248738 0.94202092 0.76838077] \n",
            "train score =  [0.00808443 0.08793022 0.00648866 0.01095671] \n",
            "test score =  [6.68355146e-04 2.04730066e-01 1.46419464e-04 9.53140193e-04]\n",
            "2  time took -  334.73840260505676 \n",
            "train_loss =  [0.90720696 0.55823327 0.82458723 0.66660186] \n",
            "test_loss =  [0.88650907 0.47268154 0.72958807 0.63495002] \n",
            "train score =  [0.01977812 0.35232923 0.0005051  0.13556608] \n",
            "test score =  [0.         0.27610694 0.         0.14955263]\n",
            "3  time took -  334.49046564102173 \n",
            "train_loss =  [0.79024566 0.42466221 0.69208882 0.57787752] \n",
            "test_loss =  [0.75054038 0.37120604 0.65338301 0.59011728] \n",
            "train score =  [2.65900736e-02 4.52522071e-01 2.09817267e-05 3.23655952e-01] \n",
            "test score =  [0.         0.46130986 0.         0.16058273]\n",
            "4  time took -  334.50776720046997 \n",
            "train_loss =  [0.71710919 0.28035561 0.62396456 0.48167895] \n",
            "test_loss =  [0.71879462 0.25132509 0.61892881 0.50121429] \n",
            "train score =  [2.80112970e-05 5.99169464e-01 0.00000000e+00 4.44865999e-01] \n",
            "test score =  [0.         0.57016587 0.         0.47425847]\n",
            "5  time took -  334.4937233924866 \n",
            "train_loss =  [0.6600561  0.20579585 0.60337031 0.40872088] \n",
            "test_loss =  [0.64849127 0.20486992 0.65223076 0.38687308] \n",
            "train score =  [0.01172052 0.64989083 0.00241645 0.52283065] \n",
            "test score =  [9.99839882e-03 5.74933800e-01 6.25195374e-05 6.12062446e-01]\n",
            "6  time took -  334.58530163764954 \n",
            "train_loss =  [0.61066476 0.17160442 0.58001289 0.32216897] \n",
            "test_loss =  [0.64775921 0.23352973 0.61408614 0.31335917] \n",
            "train score =  [0.24030096 0.67572496 0.00843737 0.57881288] \n",
            "test score =  [0.10007469 0.57532888 0.00241137 0.57553442]\n",
            "7  time took -  334.5868036746979 \n",
            "train_loss =  [0.58092931 0.14866257 0.55072746 0.44144708] \n",
            "test_loss =  [0.56899585 0.15792224 0.73605759 0.57542595] \n",
            "train score =  [0.27933525 0.69300731 0.13664306 0.36916868] \n",
            "test score =  [0.2294945  0.65308469 0.02680149 0.01941799]\n",
            "8  time took -  334.4757082462311 \n",
            "train_loss =  [0.52081164 0.13208859 0.56959645 0.46322812] \n",
            "test_loss =  [0.55662516 0.20581704 0.54089272 0.54105324] \n",
            "train score =  [0.41605883 0.71639426 0.00405007 0.22405546] \n",
            "test score =  [2.14959776e-01 5.81222322e-01 3.20307495e-04 1.98082894e-01]\n",
            "9  time took -  334.38973021507263 \n",
            "train_loss =  [0.45740564 0.11820139 0.50321559 0.28480369] \n",
            "test_loss =  [0.48816482 0.14345151 0.55953994 0.68448773] \n",
            "train score =  [0.53610175 0.73573906 0.20367776 0.53549558] \n",
            "test score =  [0.33595795 0.70083129 0.31039049 0.60893391]\n",
            "10  time took -  334.5242087841034 \n",
            "train_loss =  [0.38293034 0.11946535 0.5380664  0.22542228] \n",
            "test_loss =  [0.40665145 0.1289799  0.56236823 0.23100356] \n",
            "train score =  [0.65712866 0.73040142 0.18974048 0.57890379] \n",
            "test score =  [5.05633180e-01 6.99764820e-01 1.13739763e-04 5.70324362e-01]\n",
            "11  time took -  334.5581486225128 \n",
            "train_loss =  [0.36681057 0.10090416 0.50532503 0.1760171 ] \n",
            "test_loss =  [0.38841349 0.12610636 0.50059586 0.22323618] \n",
            "train score =  [0.64072258 0.76466057 0.17430161 0.62285915] \n",
            "test score =  [0.4106323  0.70581749 0.10304941 0.61165786]\n",
            "12  time took -  334.408164024353 \n",
            "train_loss =  [0.29486609 0.10567781 0.40299419 0.15625164] \n",
            "test_loss =  [0.28282847 0.13260098 0.4138569  0.2196737 ] \n",
            "train score =  [0.69741454 0.75484263 0.37276733 0.65186126] \n",
            "test score =  [0.54795764 0.67891158 0.33123343 0.56028853]\n",
            "13  time took -  334.4778916835785 \n",
            "train_loss =  [0.26002071 0.08915658 0.35459271 0.15951048] \n",
            "test_loss =  [0.3379849  0.11158856 1.40179062 0.19945957] \n",
            "train score =  [0.67572951 0.78386165 0.43566979 0.64329311] \n",
            "test score =  [0.52099044 0.71677563 0.37460104 0.62209322]\n",
            "14  time took -  334.57630729675293 \n",
            "train_loss =  [0.22739064 0.08839794 0.30306951 0.15695452] \n",
            "test_loss =  [0.26107051 0.1061887  1.29587621 0.17646686] \n",
            "train score =  [0.71608006 0.78469734 0.48443751 0.64093999] \n",
            "test score =  [0.56178035 0.72873152 0.4236278  0.64325358]\n",
            "15  time took -  334.4573106765747 \n",
            "train_loss =  [0.15337145 0.09200723 0.26080214 0.14144351] \n",
            "test_loss =  [0.36447099 0.12234671 0.56631005 0.27181284] \n",
            "train score =  [0.78873176 0.77641706 0.52484199 0.65695753] \n",
            "test score =  [0.40173428 0.70826848 0.41445048 0.43877811]\n",
            "16  time took -  334.57530188560486 \n",
            "train_loss =  [0.17345316 0.0858571  0.21565803 0.13047605] \n",
            "test_loss =  [0.23442398 0.13576358 1.35845118 0.40256848] \n",
            "train score =  [0.71593286 0.78940818 0.56442346 0.67388694] \n",
            "test score =  [0.57258744 0.67019107 0.41965397 0.35863184]\n",
            "17  time took -  334.5192301273346 \n",
            "train_loss =  [0.13010321 0.08129767 0.1807957  0.1241796 ] \n",
            "test_loss =  [0.27086047 0.11280132 0.99421765 0.16272306] \n",
            "train score =  [0.7852567  0.79973117 0.61224267 0.68627382] \n",
            "test score =  [0.48385764 0.72456179 0.47910506 0.65084385]\n",
            "18  time took -  334.71670365333557 \n",
            "train_loss =  [0.09360649 0.10153588 0.16300489 0.11089217] \n",
            "test_loss =  [0.22659767 0.13306454 1.33088766 0.1746208 ] \n",
            "train score =  [0.83052837 0.75699179 0.62836092 0.70966587] \n",
            "test score =  [0.55475983 0.67246241 0.43498687 0.61003194]\n",
            "19  time took -  334.49860978126526 \n",
            "train_loss =  [0.07887944 0.08949431 0.15913135 0.1050286 ] \n",
            "test_loss =  [0.15439585 0.12604007 0.97103578 0.16601014] \n",
            "train score =  [0.85158584 0.78042085 0.63229645 0.72307397] \n",
            "test score =  [0.67846673 0.70655684 0.50929068 0.62272292]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DAP-OZCcqp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zK0qSR6BoiPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "43c9b679-236b-44c0-a196-8802a44f0fde"
      },
      "source": [
        "# max size - 512, bs - 2, lr - 0.0005, bn + tanh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0  time took -  900.8071782588959 \n",
            "train_loss =  [0.88588502 0.79897586 1.23730298 1.13471253 1.23905224 1.07641844] \n",
            "test_loss =  [0.71257704 0.53063296 1.13609627 0.85824928 1.11546308 0.9864407 ] \n",
            "train score =  [0.30116513 0.34251821 0.0220032  0.0145953  0.005514   0.02405696] \n",
            "test score =  [0.15962902 0.53898676 0.05196306 0.         0.00681989 0.02429016]\n",
            "1  time took -  900.2338981628418 \n",
            "train_loss =  [0.43594538 0.35437245 1.04930878 0.74999283 1.03981589 0.8565874 ] \n",
            "test_loss =  [0.62026321 0.20292214 0.96537592 0.66814233 0.89537281 0.7788853 ] \n",
            "train score =  [0.53771895 0.61704724 0.02316369 0.0062796  0.00563939 0.01077256] \n",
            "test score =  [1.98044062e-01 7.00012249e-01 4.26233940e-05 2.57347405e-03\n",
            " 0.00000000e+00 3.28064240e-03]\n",
            "2  time took -  899.9886522293091 \n",
            "train_loss =  [0.23253207 0.13937567 0.88113007 0.62846184 0.82098116 0.69228435] \n",
            "test_loss =  [0.47299188 0.1675915  0.81693655 0.58305039 0.72480642 0.68093775] \n",
            "train score =  [6.97137028e-01 7.26195168e-01 4.89451335e-04 7.28070455e-02\n",
            " 1.13846280e-04 2.92100639e-02] \n",
            "test score =  [0.30801905 0.71307102 0.         0.06189872 0.         0.03867895]\n",
            "3  time took -  900.0337374210358 \n",
            "train_loss =  [0.15247153 0.10334587 0.75319352 0.5274225  0.67831917 0.62690206] \n",
            "test_loss =  [0.38975303 0.09122564 0.7161357  0.43711752 0.63478611 0.61083947] \n",
            "train score =  [0.75430652 0.75067747 0.03659326 0.24256069 0.         0.12308364] \n",
            "test score =  [0.37354373 0.75949178 0.0511576  0.39087055 0.         0.19048256]\n",
            "4  time took -  899.8556151390076 \n",
            "train_loss =  [0.11670017 0.08869667 0.67557058 0.37985928 0.61294782 0.54342662] \n",
            "test_loss =  [0.51955695 0.08197824 0.64371618 0.31094874 0.59146759 0.56719002] \n",
            "train score =  [0.78770619 0.76850211 0.12696077 0.43890914 0.         0.29400825] \n",
            "test score =  [0.36110831 0.77472319 0.12028133 0.53879765 0.         0.24215448]\n",
            "5  time took -  899.8848443031311 \n",
            "train_loss =  [0.08908225 0.07646459 0.62987776 0.30134527 0.58323995 0.47552088] \n",
            "test_loss =  [0.76992754 0.08776828 0.63886782 0.21413941 0.56549585 0.51564191] \n",
            "train score =  [8.20588821e-01 7.88156065e-01 2.16035964e-01 5.06137137e-01\n",
            " 2.37574314e-05 4.02498264e-01] \n",
            "test score =  [2.93248235e-01 7.71815226e-01 1.69814337e-04 6.14703874e-01\n",
            " 0.00000000e+00 2.80036612e-01]\n",
            "6  time took -  899.8805239200592 \n",
            "train_loss =  [0.0943624  0.07788825 0.60612733 0.23283354 0.56414944 0.40427292] \n",
            "test_loss =  [1.25883994 0.07475125 0.57220943 0.18540554 0.54075413 0.50056705] \n",
            "train score =  [0.81054926 0.78844736 0.08164803 0.56652211 0.00450662 0.47183744] \n",
            "test score =  [0.32018284 0.78915184 0.16903663 0.62453268 0.01262501 0.25147721]\n",
            "7  time took -  899.7239174842834 \n",
            "train_loss =  [0.06582507 0.07215822 0.52500692 0.17833652 0.54710294 0.33703136] \n",
            "test_loss =  [0.61484835 0.07383792 0.46122881 0.15077253 0.54068002 0.40989315] \n",
            "train score =  [0.85531488 0.7956893  0.40639115 0.63280868 0.10818513 0.51951997] \n",
            "test score =  [0.34193006 0.79309669 0.49673556 0.66273743 0.03019432 0.40325475]\n",
            "8  time took -  899.7667181491852 \n",
            "train_loss =  [0.05936346 0.06461731 0.45953537 0.16129826 0.50857911 0.27471059] \n",
            "test_loss =  [0.63773719 0.06862934 0.40586966 0.13679717 0.48975191 0.33875355] \n",
            "train score =  [0.86447464 0.81360673 0.54383014 0.65124724 0.23600384 0.56890668] \n",
            "test score =  [0.30551321 0.80080156 0.55837302 0.69597946 0.30577033 0.46336308]\n",
            "9  time took -  899.8489215373993 \n",
            "train_loss =  [0.0640047  0.06117704 0.38438637 0.15009108 0.45066083 0.23327398] \n",
            "test_loss =  [0.49314277 0.06973375 0.34069921 0.18818342 0.39294443 0.35457093] \n",
            "train score =  [0.85648161 0.82115095 0.65072295 0.66402999 0.40125193 0.58792366] \n",
            "test score =  [0.44118053 0.79756022 0.58586171 0.57770724 0.54455067 0.46430422]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XN68cU1t4uhp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "e0a0d231-607c-436d-d646-bdcf28c308ff"
      },
      "source": [
        "# max size - 512, lr - 0.0005, bs - 4, Unet with relu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  time took -  721.6788597106934 \n",
            "train_loss =  [0.6389396  0.59311313 1.12914431 0.71818613 0.82036042 0.84664015] \n",
            "test_loss =  [1.33673537 0.35569334 0.61198898 0.60306305 0.55575149 0.60353431] \n",
            "train score =  [0.1311722  0.00034535 0.00721091 0.         0.         0.00168007] \n",
            "test score =  [0.02926223 0.         0.         0.         0.         0.        ]\n",
            "1  time took -  721.0491104125977 \n",
            "train_loss =  [0.27287945 0.1754974  0.61857249 0.46952755 0.53219959 0.56517482] \n",
            "test_loss =  [3.37140069 0.11486308 0.60206729 0.50052358 0.53908552 0.56468886] \n",
            "train score =  [0.52796348 0.56558197 0.         0.16038902 0.         0.        ] \n",
            "test score =  [0.43217423 0.69087778 0.         0.3209337  0.         0.        ]\n",
            "2  time took -  720.9163219928741 \n",
            "train_loss =  [0.15841827 0.11271382 0.59817462 0.28714283 0.52224577 0.54215328] \n",
            "test_loss =  [0.67893372 0.10322325 0.64312099 0.38330916 0.53627023 0.51429862] \n",
            "train score =  [0.6848175  0.69273944 0.         0.42984783 0.         0.        ] \n",
            "test score =  [0.47174861 0.71180023 0.         0.4896256  0.         0.        ]\n",
            "3  time took -  720.8408095836639 \n",
            "train_loss =  [0.09632691 0.09216868 0.59016402 0.17818633 0.4753804  0.45229849] \n",
            "test_loss =  [4.04653105 0.10802969 0.58589185 0.19297298 0.45076159 0.24955033] \n",
            "train score =  [0.79062941 0.73790763 0.         0.59329464 0.02902763 0.11980296] \n",
            "test score =  [0.47307332 0.7042779  0.         0.59824844 0.11656758 0.53105278]\n",
            "4  time took -  720.7410435676575 \n",
            "train_loss =  [0.10740665 0.08627834 0.5569205  0.15186049 0.42270344 0.4117457 ] \n",
            "test_loss =  [3.09766181 0.08968298 0.4899943  0.19190833 0.61664148 0.23016398] \n",
            "train score =  [0.77581554 0.75243634 0.         0.64277336 0.27801688 0.29662953] \n",
            "test score =  [0.41347159 0.74571392 0.         0.58855409 0.26816123 0.49255516]\n",
            "5  time took -  720.6759684085846 \n",
            "train_loss =  [0.10302793 0.07912652 0.41544339 0.12459137 0.37776587 0.28867213] \n",
            "test_loss =  [2.27521912 0.0828873  0.32176423 0.23809921 0.53287357 0.11897307] \n",
            "train score =  [0.7839391  0.7703618  0.12846415 0.69551149 0.34175889 0.38833517] \n",
            "test score =  [0.46777637 0.76175209 0.28678796 0.60067876 0.2697977  0.67496621]\n",
            "6  time took -  720.6920711994171 \n",
            "train_loss =  [0.07121661 0.07353457 0.29485952 0.11348581 0.30229865 0.21422239] \n",
            "test_loss =  [6.34341128 0.08288276 0.21549974 0.25533456 0.32895202 0.20957733] \n",
            "train score =  [0.83309241 0.78450912 0.49205275 0.71949395 0.34418085 0.51025888] \n",
            "test score =  [0.49353937 0.76310536 0.57959837 0.60891795 0.30926508 0.56294693]\n",
            "7  time took -  720.6441338062286 \n",
            "train_loss =  [0.05996572 0.06923668 0.20817021 0.10447384 0.25895793 0.19169474] \n",
            "test_loss =  [2.53304034 0.07931881 0.19111164 0.23245087 0.36840912 0.14985087] \n",
            "train score =  [0.85805101 0.79622846 0.56898795 0.73962222 0.38755391 0.54988122] \n",
            "test score =  [0.49333965 0.7719268  0.62186843 0.62699877 0.34196964 0.65488315]\n",
            "8  time took -  720.7113869190216 \n",
            "train_loss =  [0.07175399 0.06784983 0.17844853 0.09945411 0.25616557 0.1745662 ] \n",
            "test_loss =  [0.55821611 0.07754867 0.13616124 0.33472843 0.3632339  0.14172333] \n",
            "train score =  [0.85004842 0.79950102 0.60683118 0.74885242 0.40583643 0.58105666] \n",
            "test score =  [0.41609992 0.7745249  0.67172202 0.61139548 0.35018196 0.6766207 ]\n",
            "9  time took -  720.6816694736481 \n",
            "train_loss =  [0.09220444 0.06389337 0.17434414 0.0951278  0.23392017 0.16799581] \n",
            "test_loss =  [6.76928395 0.08961353 0.17851743 0.14578369 0.37590037 0.12104895] \n",
            "train score =  [0.80350886 0.81003564 0.61717007 0.75781658 0.43275174 0.59388137] \n",
            "test score =  [0.49880897 0.74719332 0.66898115 0.67572259 0.35169776 0.66820484]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}